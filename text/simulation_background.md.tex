%!TEX TS-program = ../make.zsh

\section{Simulation Background}
\label{sec:simulation_background}

\subsection{Monte-Carlo Simulations}
\label{sec:monte_carlo}

% Sources: Lexikon der Physik, Spektrum-Verlag, "Monte-Carlo-Simulation", "Gesetz der gro√üen Zahlen": \cite{physiklexikon}.

A Monte-Carlo simulation is computational method that utilizes a large amount of random numbers. The method is named after the \textit{Monte Carlo Casino} in Monaco, hinting the randomness involved in gambling. \cite{physiklexikon}

Samples of random numbers are drawn from given probability distributions. The numbers are used in deterministic calculations. The results are then evaluated to gain information about processes or quantities involved. This method is especially useful for systems with many degrees of freedom. \cite{physiklexikon}

The suitability of this method for numerical or physics problems is based on the \textit{law of large numbers}: If an experiment involving random processes is repeated $n$ times, the relative frequency $h_n(A):=\sfrac{H(A)}{n}$ of an event $A$, which occurs $H(A)$ times in total in these $n$ experiments, approaches the \textit{probability} $p(A)$ of the event $A$ for large numbers $n$ with certainty. \cite{physiklexikon}

$$
  \lim_{n \rightarrow \infty} \text{P}(|h_n(A) - p(A)| < \epsilon) = 1, \ \ \ \epsilon \in \reals
$$

In the simulations of this study, photons are propagated through the ice based on drawing random numbers from known probability distributions in order to determine in each simulation step whether to scatter or to absorb a photon, and to determine the scattering angle for each scattering process. The simulation aims for each photon and each detector module to check whether the photon hits the module in the are that is sensitve to photons, that is to say whether the photon is detected by the detector module.

The calculations in the propagation algorithm are deterministic. In principle, one could devise a mathematical function of input quantities and random variables that determines whether a photon is detected by an optical module. This task would be disproportionately complex, however, especially as the function would have to be revised for every change in the underlying models.

Technical progress concerning computational devices, graphics processing units (GPUs) in particular, allow to devide the calculations into components that are easier to model and apply those to highly parallelized large-scale simulations.

For a random-walk description of the propagation of photons, see \cite{absorption1997}. A first implementation of a photon propagation through ice is described in \cite{lundberg}. A study of propagation simulations using GPUs is presented in \cite{ppcpaper}.


\subsection{Parallal Computing on Graphics Processing Units (GPUs)}
\label{sec:parallel_computing}

Graphics processing units (GPUs) are optimized for performing simple calculations for a large number of values in parallel.

The general procedure for GPU calculations is to reserve memory on the GPU, to copy input parameters onto the GPU, perform calculations on the GPU, and then to download the results from the GPU. This procedure is efficient if the time that is spent for reserving, and copying to and from the GPU memory is short compared to the time spent with calculations on the GPU. \cite{cudacourse}

The basic units for parallelization are \textit{computational threads}. All operations within a thread are sequential, while all these operations are applied to a set of threads, called \textit{thread block}, in parallel. Each GPU may have one or several thread blocks. \cite{cudacourse}

While rapid technological progresses are achieved, GPU memory is still a considerably limited resource. In particular fast memory, that is to say memory for that reading and writing information takes a small amount of physical time, is expensive. Therefore, memory is devided in several cateogories: The \textit{local memory} that belongs only to one thread, is fastest but most limited. The \textit{shared memory}, which is common to all threads of one thread block, is slower. Next slower is the \textit{global memory}, which is common to all thread blocks on the GPU. Slowest, but in comparison to the GPU memory practically unlimited, is the \textit{host memory}, which is computer memory not on the GPU but on other components of the computer. \cite{cudacourse}

Efficient memory use is one of the key concepts for performant GPU programming. Techniques that utilize the internal optimizations of GPUs allow for further performance improvements: Using GPU-native \textit{atomic operations} such as the increment operator that increases the value of a variable by 1 is more performant than using a generic mathematical operation. GPUs support vectors with four components as native data types. Using \textit{native vectorial operations} such as a dot product is more performant than implementing the operation as mathematical function manually. Furthermore, \textit{coalesce memory access}, that is to say, each thread in a thread block reads or writes from or to a coherent memory block parallel to the other threads of the thread block, in creases memory access performance. \cite{cudacourse}

In parallel computing, the \textit{step complexity} of an algorithm is a measure of the physical time the parallelized algorithm needs to run. The \textit{work complexity} is a measure for the summed computational work that is done by all threads in that time. A pattern to avoid in this context is \textit{thread divergence} where some threads have to stay idle and wait for other threads completing their work. \cite{cudacourse}
